<!DOCTYPE html>
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta content="IE=5.0000" http-equiv="X-UA-Compatible">
  <meta name="description" content="MingBao Lin&#39;s home page">
  <meta name="keywords" content="林明宝,Mingbao Lin" />
  
  <link href="./imgs/tlzdoc.css" rel="stylesheet" type="text/css">
  <title>Mingbao Lin's Homepage--林明宝的个人主页</title>
  <meta name="GENERATOR" content="MSHTML 11.00.10570.1001">
</head>


<body>
  <div id="layout-content" style="margin-top: 25px;">
  <table>
    <tbody>
    <tr>
      <td>
        &nbsp;&nbsp;&nbsp;<img width="180" src="./imgs/marlin.jpeg" border="100">
      </td>	
      <td width="670">
        <div id="toptitle">
        <h1>&nbsp;&nbsp;&nbsp; Mingbao Lin &nbsp; 林明宝<a name="top"></a></h1>
		</div>
         &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  Senior Researcher <br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Tencent Youtu Lab<br>
        <p>
        <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Email: linmb001[at]outlook[dot]com
 <!--       <a href="mailto:linmb001@outlook.com">linmb001@outlook.com</a>	-->	
        <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
	&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://github.com/lmbxmu" target="_blank">[Github]</a>
	&nbsp;&nbsp;<a href="https://scholar.google.com/citations?user=Dp3L1bsAAAAJ&hl=en&oi=ao" target="_blank">[Scholar]</a>	
  <!--      &nbsp;&nbsp;<a href="#" target="_blank">[Ph.D. Thesis, in Chinese]</a>		-->
        <br><br></p>
		&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  <font color="red">Academic life is not all, but it can be a part.</font>
      </td>
    </tr>
    <tr></tr></tbody>
  </table>
  <div id="layout-content" style="margin-top: 25px;">


<h4>[<a style=" color:#9D849A;" href="#biography">Biography</a>] [<a style=" color:#9D849A;" href="#news">Latest News</a>] [<a style=" color:#9D849A;" href="#publications">Publications</a>] <!--[<a style=" color:#9D849A;" href="#patents">Patents</a>] -->
[<a style=" color:#9D849A;" href="#activities">Professional Activities</a>] [<a style=" color:#9D849A;" href="#awards">Major Awards</a>] [<a style=" color:#9D849A;" href="#statistics">Statistics</a>]</h4>


<h2>Biography<a name="biography"></a>&nbsp;&nbsp;&nbsp;<a style=" color:#9D849A; font-size:15px;" href="#top">[back top]</a></h2>
  <p style="text-indent:2em;"> I am a senior researcher at Tencent, where I work on computer vision and information retrieval. 
      I finished the M.S.-Ph.D. study and obtained my Ph.D. degree from Xiamen University in 2022, advised by <a href="https://mac.xmu.edu.cn/rrji_en/" target="_blank">Prof. Rongrong Ji</a>.
	  Earlier, I received the B.S. degree from Fuzhou University in 2016.
  </p>
  <p style="text-indent:2em;">My recent research interests are to develop efficient vision models, image/text retrieval, as well as vision/language pretraining.</p>

<ul>  
  <li> 07/2022 -- Now: Senior Researcher, <a href="https://open.youtu.qq.com/#/open"  target="_blank">Tencent Youtu Lab</a>, Shanghai, China </li>
  <li> 09/2019 -- 06/2022: Research Intern, <a href="https://www.pcl.ac.cn/" target="_blank">Peng Cheng Lab</a>, Shenzhen, China </li>
  <li> 09/2018 -- 06/2022: Ph.D. in Intelligence Science and Technology, <a href="https://mac.xmu.edu.cn/"  target="_blank">MAC Lab</a>, Xiamen University, Xiamen, China</li>
  <li> 09/2016 -- 06/2018: M.S. in Computer Technology, <a href="https://mac.xmu.edu.cn/"  target="_blank">MAC Lab</a>, Xiamen University, Xiamen, China </li>  
  <li> 09/2012 -- 06/2016: B.S. in Computer Science and Technology, Fuzhou University, Fuzhou, China </li>
</ul>


<h2>Latest News<a name="news"></a>&nbsp;&nbsp;&nbsp;<a style=" color:#9D849A; font-size:15px;" href="#top">[back top]</a></h2>
<ul>
  <li> 01/2023: One paper accepted by ICLR 2023</li>
  <li> 11/2022: Three papers (including two oral papers) accepted by AAAI 2023</li>
  <li> 10/2022: One paper accepted by IEEE TPAMI</li>
  <li> 09/2022: One paper accepted by NeurIPS 2022</li>
  <li> 08/2022: Outstanding contributions to the development of IEEE Standard 2941<sup style="vertical-align:top;"><font style="font-size:1px">TM</font></sup> - 2022</li>
  <li> 07/2022: One paper accepted by IEEE TPAMI</li>
  <li> 07/2022: Five papers (including one oral paper) accepted by ECCV 2022</li>
  <li> 07/2022: Senior Researcher, Tencent, Shanghai, China</li>
  <li> 06/2022: Outstanding Ph.D. Graduate Student, Xiamen University</li>
  <li> 05/2022: One paper accepted by IEEE TPAMI</li>
  <li> 03/2022: One paper accepted by CVPR 2022</li>
  <li> 03/2022: One paper accepted by IEEE TMM </li>  
  <li> 02/2022 -- 03/2022: Three papers accepted by IEEE TNNLS </li>
</ul>


<h2>Publications<a name="publications"></a>&nbsp;&nbsp;&nbsp;<a style=" color:#9D849A; font-size:15px;" href="#top">[back top]</a></h2>
<h3>Journal</h3>
<table class="pub_table">
  <tbody>
  
  <tr>
    <td class="pub_td1">012<img src="./imgs/siman.jpg" class="papericon"></td>
    <td class="pub_td2"> <font color="goldenrod">Mingbao Lin</font>, Rongrong Ji<sup>✉</sup>, Zihan Xu, Baochang Zhang, Fei Chao, Chia-Wen Lin, Ling Shao
      <br><b>SiMaN: Sign-to-Magnitude Network Binarization</b>
      <br>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2022
      <br>   
      [<a href="https://ieeexplore.ieee.org/abstract/document/9913704" target="_blank">pdf</a>]			  
      [<a href="http://arxiv.org/abs/2102.07981" target="_blank">arXiv</a>]
      [<a href="https://github.com/lmbxmu/SiMaN" target="_blank">code</a>]
    </td>
  </tr>
  
  <tr>
    <td class="pub_td1">011<img src="./imgs/1xn.jpg" class="papericon"></td>
    <td class="pub_td2"> <font color="goldenrod">Mingbao Lin</font>, Yuxin Zhang, Yuchao Li, Bohong Chen, Fei Chao, Mengdi Wang, Shen Li, Yonghong Tian, Rongrong Ji<sup>✉</sup>
      <br><b>1xN Pattern for Pruning Convolutional Neural Networks</b>
      <br>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2022
      <br> 
      [<a href="https://ieeexplore.ieee.org/document/9847369" target="_blank">pdf</a>]		  
      [<a href="https://arxiv.org/abs/2105.14713" target="_blank">arXiv</a>]
      [<a href="https://github.com/lmbxmu/1xN" target="_blank">code</a>]
    </td>
  </tr>
	  
  <tr>
    <td class="pub_td1">010<img src="./imgs/lecnet.png" class="papericon"></td>
    <td class="pub_td2">Boyu Yang, <font color="goldenrod">Mingbao Lin</font>, Yunxiao Zhang, Binghao Liu, Xiaodan Liang, Rongrong Ji, Qixiang Ye<sup>✉</sup>
      <br><b>Dynamic Support Network for Few-shot Class Incremental Learning</b>
      <br>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2022
      <br>
      [<a href="https://ieeexplore.ieee.org/document/9779071" target="_blank">pdf</a>]	 
      [<a href="https://arxiv.org/abs/2104.02281" target="_blank">arXiv</a>]	  
      [<a href="https://github.com/Yang-Bob/DSN" target="_blank">code</a>]                    
    </td>
  </tr>   	 
	  
  <tr>
    <td class="pub_td1">009<img src="./imgs/clr-rnf.png" class="papericon"></td>
    <td class="pub_td2"> <font color="goldenrod">Mingbao Lin</font>, Liujuan Cao<sup>✉</sup>, Yuxin Zhang, Ling Shao, Chia-Wen Lin, Rongrong Ji 
      <br><b>Pruning Networks with Cross-Layer Ranking & k-Reciprocal Nearest Filters</b>
      <br>IEEE Transactions on Neural Networks and Learning Systems (TNNLS), 2022
      <br>
      [<a href="https://ieeexplore.ieee.org/document/9737040" target="_blank">pdf</a>]
	  [<a href="https://arxiv.org/abs/2202.07190" target="_blank">arXiv</a>]
	  [<a href="https://github.com/lmbxmu/CLR-RNF" target="_blank">code</a>]
    </td>
  </tr>

  <tr>
    <td class="pub_td1">008<img src="./imgs/dmad.jpg" class="papericon"></td>
    <td class="pub_td2"> Shaojie Li, <font color="goldenrod">Mingbao Lin</font>, Yan Wang, Fei Chao, Ling Shao, Rongrong Ji<sup>✉</sup>
      <br><b>Learning Efficient GANs for Image Translation via Differentiable Masks and co-Attention Distillation</b>
      <br>IEEE Transactions on Multimedia (TMM), 2022
      <br>
      [<a href="https://ieeexplore.ieee.org/document/9729410" target="_blank">pdf</a>]                    
      [<a href="https://arxiv.org/abs/2011.08382" target="_blank">arXiv</a>]
      [<a href="https://github.com/SJLeo/DMAD" target="_blank">code</a>]
    </td>
  </tr>

  <tr>
    <td class="pub_td1">007<img src="./imgs/ffsd.png" class="papericon"></td>
    <td class="pub_td2"> Shaojie Li, <font color="goldenrod">Mingbao Lin</font>, Yan Wang, Yongjian Wu, Yonghong Tian, Ling Shao, Rongrong Ji<sup>✉</sup>
      <br><b>Distilling a Powerful Student Model via Online Knowledge Distillation</b>
      <br>IEEE Transactions on Neural Networks and Learning Systems (TNNLS), 2022
      <br>
      [<a href="https://ieeexplore.ieee.org/document/9729452" target="_blank">pdf</a>]                    
      [<a href="https://arxiv.org/abs/2103.14473" target="_blank">arXiv</a>]
      [<a href="https://github.com/SJLeo/FFSD" target="_blank">code</a>]
    </td>
  </tr>

  <tr>
    <td class="pub_td1">006<img src="./imgs/white.jpg" class="papericon"></td>
    <td class="pub_td2"> Yuxin Zhang, <font color="goldenrod">Mingbao Lin</font>, Chia-Wen Lin, Jie Chen, Yongjian Wu, Yonghong Tian, Rongrong Ji<sup>✉</sup>
      <br><b>Carrying out CNN Channel Pruning in a White Box</b>
      <br>IEEE Transactions on Neural Networks and Learning Systems (TNNLS), 2022
      <br>
      [<a href="https://ieeexplore.ieee.org/document/9712474" target="_blank">pdf</a>]                    
      [<a href="https://arxiv.org/abs/2104.11883" target="_blank">arXiv</a>]
      [<a href="https://github.com/zyxxmu/White-Box" target="_blank">code</a>]
    </td>
  </tr>
	  
  <tr>
    <td class="pub_td1">005<img src="./imgs/epruner.jpg" class="papericon"></td>
    <td class="pub_td2"> <font color="goldenrod">Mingbao Lin</font>, Rongrong Ji<sup>✉</sup>, Shaojie Li, Yan Wang, Yongjian Wu, Feiyue Huang, Qixiang Ye
      <br><b>Network Pruning using Adaptive Exemplar Filters</b>
      <br>IEEE Transactions on Neural Networks and Learning Systems (TNNLS), 2021
      <br>
      [<a href="https://ieeexplore.ieee.org/document/9448300" target="_blank">pdf</a>]                    
      [<a href="https://arxiv.org/abs/2101.07985" target="_blank">arXiv</a>]
      [<a href="https://github.com/lmbxmu/EPruner" target="_blank">code</a>]
    </td>
  </tr>

  <tr>
    <td class="pub_td1">004<img src="./imgs/filtersketch.jpg" class="papericon"></td>
    <td class="pub_td2"> <font color="goldenrod">Mingbao Lin</font>, Liujuan Cao<sup>✉</sup>, Shaojie Li, Qixiang Ye, Yonghong Tian, Jianzhuang Liu, Qi Tian, Rongrong Ji
      <br><b>Filter Sketch for Network Pruning</b>
      <br>IEEE Transactions on Neural Networks and Learning Systems (TNNLS), 2021
      <br>
      [<a href="https://ieeexplore.ieee.org/document/9454340" target="_blank">pdf</a>]                    
      [<a href="https://arxiv.org/abs/2001.08514" target="_blank">arXiv</a>]
      [<a href="https://github.com/lmbxmu/FilterSketch" target="_blank">code</a>]
    </td>
  </tr>
  
  <tr>
    <td class="pub_td1">003<img src="./imgs/fcoh.jpg" class="papericon"></td>
    <td class="pub_td2"> <font color="goldenrod">Mingbao Lin</font>, Rongrong Ji<sup>✉</sup>, Xiaoshuai Sun, Baochang Zhang, Feiyue Huang, Yonghong Tian, Dacheng Tao
      <br><b>Fast Class-wise Updating for Online Hashing</b>
      <br>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2020
      <br>
      [<a href="https://ieeexplore.ieee.org/document/9279285" target="_blank">pdf</a>]                    
      [<a href="https://arxiv.org/abs/2012.00318" target="_blank">arXiv</a>]
      [<a href="https://github.com/lmbxmu/mycode" target="_blank">code</a>]
    </td>
  </tr>
 
  <tr>
    <td class="pub_td1">002<img src="./imgs/hmoh.jpg" class="papericon"></td>
    <td class="pub_td2"> <font color="goldenrod">Mingbao Lin</font>, Rongrong Ji<sup>✉</sup>, Hong Liu, Xiaoshuai Sun, Shen Chen, Qi Tian
      <br><b>Hadamard Matrix Guided Online Hashing</b>
      <br>International Journal of Computer Vision (IJCV), 2020
      <br>
      [<a href="https://link.springer.com/article/10.1007/s11263-020-01332-z" target="_blank">pdf</a>]                    
      [<a href="https://arxiv.org/abs/1905.04454" target="_blank">arXiv</a>]
      [<a href="https://github.com/lmbxmu/mycode" target="_blank">code</a>]
      [<a href="https://mp.weixin.qq.com/s/MpEmG26uDRWGri6d0rk2VA" target="_blank">AI科技评论</a>]	  
    </td>
  </tr>
  
  <tr>
    <td class="pub_td1">001<img src="./imgs/splh.jpg" class="papericon"></td>
    <td class="pub_td2"> <font color="goldenrod">Mingbao Lin</font>, Rongrong Ji<sup>✉</sup>, Shen Chen, Xiaoshuai Sun, Chia-Wen Lin
      <br><b>Similarity-Preserving Linkage Hashing for Online Image Retrieval</b>
      <br>IEEE Transactions on Image Processing (TIP), 2020
      <br>
      [<a href="https://ieeexplore.ieee.org/document/9046296" target="_blank">pdf</a>]                    
      [<a href="https://github.com/lmbxmu/mycode" target="_blank">code</a>]
    </td>
  </tr>

  </tbody>
</table>

<h3>Conference</h3>
<table class="pub_table">
  <tbody>
  
  <tr>
    <td class="pub_td1">018<img src="./imgs/dda.png" class="papericon"></td>
    <td class="pub_td2">Yuxin Zhang, <font color="goldenrod">Mingbao Lin</font>, Xunchao Li, Han Liu, Guozhi Wang, Fei Chao, Shuai Ren, Yafei Wen, Xiaoxin Chen, Rongrong Ji<sup>✉</sup>
      <br><b>Real-Time Image Demoir&eacuteing on Mobile Devices</b>
      <br>International Conference on Learning Representations (ICLR), 2023
      <br>
	  [<a href="https://openreview.net/pdf?id=PmP_sf3JkrH" target="_blank">pdf</a>]
	  [<a href="#" target="_blank">arXiv coming</a>]
	  [<a href="https://openreview.net/forum?id=PmP_sf3JkrH" target="_blank">openreview</a>]
	  [<a href="https://github.com/zyxxmu/DDA" target="_blank">code</a>]  
    </td>
  </tr>  

  <tr>
    <td class="pub_td1">017<img src="./imgs/cfvit.png" class="papericon"></td>
    <td class="pub_td2">Mengzhao Chen, <font color="goldenrod">Mingbao Lin</font>, Ke Li, Yunhang Shen, Yongjian Wu, Fei Chao, Rongrong Ji<sup>✉</sup>
      <br><b>CF-ViT: A General Coarse-to-Fine Method for Vision Transformer</b>
      <br>AAAI Conference on Artificial Intelligence (AAAI, Oral), 2023
      <br>
      [<a href="#" target="_blank">pdf coming</a>] 	
	  [<a href="https://arxiv.org/abs/2203.03821" target="_blank">arXiv</a>]
	  [<a href="https://github.com/ChenMnZ/CF-ViT" target="_blank">code</a>]
	  [<a href="https://zhuanlan.zhihu.com/p/585108361" target="_blank">知乎</a>]
	  [<a href="https://mp.weixin.qq.com/s/dg0A4Eq4NL1N20G8Pxvdkw" target="_blank">将门创投</a>]	  
    </td>
  </tr>
  
  <tr>
    <td class="pub_td1">016<img src="./imgs/rebnn.png" class="papericon"></td>
    <td class="pub_td2">Sheng Xu<sup>*</sup>, Yanjing Li<sup>*</sup>, Teli Ma<sup>*</sup>, <font color="goldenrod">Mingbao Lin</font>, Hao Dong, Baochang Zhang<sup>✉</sup>, Peng Gao, Jinhu Lu
      <br><b>Resilient Binary Neural Network</b>
      <br>AAAI Conference on Artificial Intelligence (AAAI, Oral), 2023
      <br>
      [<a href="#" target="_blank">pdf coming</a>]   	  
	  [<a href="https://arxiv.org/abs/2302.00956" target="_blank">arXiv</a>]
	  [<a href="https://github.com/SteveTsui/ReBNN" target="_blank">code</a>]
	  (<sup>*</sup> Equal Contribution)
    </td>
  </tr>
  
  <tr>
    <td class="pub_td1">015<img src="./imgs/eoid.png" class="papericon"></td>
    <td class="pub_td2">Mingrui Wu, Jiaxin Gu, Yunhang Shen, <font color="goldenrod">Mingbao Lin</font>, Chao Chen, Xiaoshuai Sun<sup>✉</sup>
      <br><b>End-to-End Zero-Shot HOI Detection via Vision and Language Knowledge Distillation</b>
      <br>AAAI Conference on Artificial Intelligence (AAAI), 2023
      <br>
      [<a href="#" target="_blank">pdf coming</a>]   	
	  [<a href="https://arxiv.org/abs/2204.03541" target="_blank">arXiv</a>]
	  [<a href="https://github.com/mrwu-mac/EoID" target="_blank">code</a>]
    </td>
  </tr>    

  <tr>
    <td class="pub_td1">014<img src="./imgs/lbc.png" class="papericon"></td>
    <td class="pub_td2">Yuxin Zhang, <font color="goldenrod">Mingbao Lin</font>, Zhihang Lin, Yiting Luo, Ke Li, Fei Chao, Yongjian Wu, Rongrong Ji<sup>✉</sup>
      <br><b>Learning Best Combination for Efficient N:M Sparsity</b>
      <br>Conference on Neural Information Processing Systems (NeurIPS), 2022
      <br>
      [<a href="https://openreview.net/pdf?id=tbdk6XLYmZj" target="_blank">pdf</a>]   
	  [<a href="https://arxiv.org/abs/2206.06662" target="_blank">arXiv</a>]
	  [<a href="https://openreview.net/forum?id=tbdk6XLYmZj" target="_blank">openreview</a>]
	  [<a href="https://github.com/zyxxmu/LBC" target="_blank">code</a>]
    </td>
  </tr>    
  
  <tr>
    <td class="pub_td1">013<img src="./imgs/arm.png" class="papericon"></td>
    <td class="pub_td2">Bohong Chen, <font color="goldenrod">Mingbao Lin</font>, Kekai Sheng, Mengdan Zhang, Peixian Chen, Ke Li, Liujuan Cao<sup>✉</sup>, Rongrong Ji
      <br><b>ARM: Any-Time Super-Resolution Method</b>
      <br>European Conference on Computer Vision (ECCV), 2022
      <br>
      [<a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136790248.pdf" target="_blank">pdf</a>|<a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136790248-supp.pdf" target="_blank">supp</a>]      
      [<a href="https://arxiv.org/abs/2203.10812" target="_blank">arXiv</a>]
      [<a href="https://github.com/chenbong/ARM-Net" target="_blank">code</a>]
	  [<a href="https://zhuanlan.zhihu.com/p/573021183" target="_blank">知乎</a>]	  
      [<a href="https://www.cnblogs.com/huang-hz/p/16598895.html" target="_blank">博客园</a>]	
      [<a href="https://mp.weixin.qq.com/s/lAcsg2YZJ-oGzlIpCaDe8w" target="_blank">AIWalker</a>]		  
    </td>
  </tr> 

  <tr>
    <td class="pub_td1">012<img src="./imgs/ddtb.png" class="papericon"></td>
    <td class="pub_td2">Yunshan Zhong, <font color="goldenrod">Mingbao Lin</font>, Xunchao Li, Ke Li, Yunhang Shen, Fei Chao, Yongjian Wu, Rongrong Ji<sup>✉</sup>
      <br><b>Dynamic Dual Trainable Bounds for Ultra-low Precision Super-Resolution</b>
      <br>European Conference on Computer Vision (ECCV), 2022
      <br>
      [<a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136780001.pdf" target="_blank">pdf</a>|<a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136780001-supp.pdf" target="_blank">supp</a>]    
      [<a href="https://arxiv.org/abs/2203.03844" target="_blank">arXiv</a>]                    
      [<a href="https://github.com/zysxmu/DDTB" target="_blank">code</a>]
	  [<a href="https://zhuanlan.zhihu.com/p/542200850" target="_blank">知乎</a>]
    </td>
  </tr>
  
  <tr>
    <td class="pub_td1">011<img src="./imgs/kcd.png" class="papericon"></td>
    <td class="pub_td2">Chenxin Li, <font color="goldenrod">Mingbao Lin</font>, Zhiyuan Ding, Nie Lin, Yihong Zhuang, Yue Huang<sup>✉</sup>, Xinhao Ding, Liujuan Cao
      <br><b>Knowledge Condensation Distillation</b>
      <br>European Conference on Computer Vision (ECCV), 2022
      <br>
      [<a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136710019.pdf" target="_blank">pdf</a>|<a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136710019-supp.pdf" target="_blank">supp</a>]  
      [<a href="https://arxiv.org/abs/2207.05409" target="_blank">arXiv</a>]                    
      [<a href="https://github.com/dzy3/KCD" target="_blank">code</a>]
	  [<a href="https://zhuanlan.zhihu.com/p/543261508" target="_blank">知乎</a>]
    </td>
  </tr>

  <tr>
    <td class="pub_td1">010<img src="./imgs/fdda.jpg" class="papericon"></td>
    <td class="pub_td2"> Yunshan Zhong, <font color="goldenrod">Mingbao Lin</font>, Mengzhao Chen, Ke Li, Yunhang Shen, Fei Chao, Yongjian Wu, Rongrong Ji<sup>✉</sup>
      <br><b>Fine-grained Data Distribution Alignment for Post-Training Quantization</b>
      <br>European Conference on Computer Vision (ECCV), 2022
      <br> 
      [<a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136710070.pdf" target="_blank">pdf</a>|<a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136710070-supp.pdf" target="_blank">supp</a>]   	  
      [<a href="http://arxiv.org/abs/2109.04186" target="_blank">arXiv</a>]
      [<a href="https://github.com/zysxmu/FDDA" target="_blank">code</a>]
    </td>
  </tr>  
  
   <tr>
    <td class="pub_td1">009<img src="./imgs/seqtr.png" class="papericon"></td>
    <td class="pub_td2">Chaoyang Zhu, Yiyi Zhou, Yunhang Shen, Gen Luo, Xingjia Pan, <font color="goldenrod">Mingbao Lin</font>, Chao Chen, Liujuan Cao<sup>✉</sup>, Xiaoshuai Sun, Rongrong Ji
      <br><b>SeqTR: A Simple yet Universal Network for Visual Grounding</b>
      <br>European Conference on Computer Vision (ECCV, Oral), 2022
      <br>
	  [<a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136950593.pdf" target="_blank">pdf</a>]     
	  [<a href="https://arxiv.org/abs/2203.16265" target="_blank">arXiv</a>]
	  [<a href="https://github.com/sean-zhuh/SeqTR" target="_blank">code</a>]
	  [<a href="https://zhuanlan.zhihu.com/p/580284325" target="_blank">知乎</a>]
    </td>
  </tr>  
  
  <tr>
    <td class="pub_td1">008<img src="./imgs/intraq.png" class="papericon"></td>
    <td class="pub_td2"> Yunshan Zhong, <font color="goldenrod">Mingbao Lin</font>, Gongrui Nan, Jianzhuang Liu, Baochang Zhang, Yonghong Tian, Rongrong Ji<sup>✉</sup>
      <br><b>IntraQ: Learning Synthetic Images with Intra-Class Heterogeneity for Zero-Shot Network Quantization</b>
      <br>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2022
      <br>
      [<a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Zhong_IntraQ_Learning_Synthetic_Images_With_Intra-Class_Heterogeneity_for_Zero-Shot_Network_CVPR_2022_paper.pdf" target="_blank">pdf</a>|<a href="https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhong_IntraQ_Learning_Synthetic_CVPR_2022_supplemental.pdf" target="_blank">supp</a>]                    
      [<a href="https://arxiv.org/abs/2111.09136" target="_blank">arXiv</a>]
      [<a href="https://github.com/zysxmu/intraq" target="_blank">code</a>]
    </td>
  </tr>

  <tr>
    <td class="pub_td1">007<img src="./imgs/recu.jpg" class="papericon"></td>
    <td class="pub_td2"> Zihan Xu, <font color="goldenrod">Mingbao Lin</font>, Jianzhuang Liu, Jie Chen, Ling Shao, Yue Gao, Yonghong Tian, Rongrong Ji<sup>✉</sup>
      <br><b>ReCU: Reviving the Dead Weights in Binary Neural Networks</b>
      <br>IEEE/CVF International Conference on Computer Vision (ICCV), 2021
      <br>
      [<a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Xu_ReCU_Reviving_the_Dead_Weights_in_Binary_Neural_Networks_ICCV_2021_paper.pdf" target="_blank">pdf</a>|<a href="https://openaccess.thecvf.com/content/ICCV2021/supplemental/Xu_ReCU_Reviving_the_ICCV_2021_supplemental.pdf" target="_blank">supp</a>]                    
      [<a href="https://arxiv.org/abs/2103.12369" target="_blank">arXiv</a>]
      [<a href="https://github.com/z-hXu/ReCU" target="_blank">code</a>]
    </td>
  </tr>

  <tr>
    <td class="pub_td1">006<img src="./imgs/rbnn.jpg" class="papericon"></td>
    <td class="pub_td2"> <font color="goldenrod">Mingbao Lin</font>, Rongrong Ji<sup>✉</sup>, Zihan Xu, Baochang Zhang, Yan Wang, Yongjian Wu, Feiyue Huang, Chia-Wen Lin
      <br><b>Rotated Binary Neural Network</b>
      <br>Conference on Neural Information Processing Systems (NeurIPS), 2020
      <br>
      [<a href="https://papers.nips.cc/paper/2020/file/53c5b2affa12eed84dfec9bfd83550b1-Paper.pdf" target="_blank">pdf</a>]                    
      [<a href="https://arxiv.org/abs/2009.13055" target="_blank">arXiv</a>]
      [<a href="https://github.com/lmbxmu/RBNN" target="_blank">code</a>]
	  [<a href="https://cloud.tencent.com/developer/article/2111144" target="_blank">腾讯云开发者社区</a>]
    </td>
  </tr>
	  
  <tr>
    <td class="pub_td1">005<img src="./imgs/hrank.png" class="papericon"></td>
    <td class="pub_td2"> <font color="goldenrod">Mingbao Lin</font>, Rongrong Ji<sup>✉</sup>, Yan Wang, Yichen Zhang, Baochang Zhang, Yonghong Tian, Ling Shao
      <br><b>HRank: Filter Pruning using High-Rank Feature Map</b>
      <br>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR, Oral), 2020
      <br>
      [<a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Lin_HRank_Filter_Pruning_Using_High-Rank_Feature_Map_CVPR_2020_paper.pdf" target="_blank">pdf</a>]                    
      [<a href="https://arxiv.org/abs/2002.10179" target="_blank">arXiv</a>]
      [<a href="https://github.com/lmbxmu/HRank" target="_blank">code_v1</a>]
      [<a href="https://github.com/lmbxmu/HRankPlus" target="_blank">code_v2</a>]	  
	  [<a href="https://mp.weixin.qq.com/s/tAF-16XK8a8DusMxEDgDtQ" target="_blank">机器之心</a>]	 
    </td>
  </tr>

  <tr>
    <td class="pub_td1">004<img src="./imgs/abcpruner.jpg" class="papericon"></td>
    <td class="pub_td2"> <font color="goldenrod">Mingbao Lin</font>, Rongrong Ji<sup>✉</sup>, Yuxin Zhang, Baochang Zhang, Yongjian Wu, Yonghong Tian
      <br><b>Channel Pruning via Automatic Structure Search</b>
      <br>International Joint Conference on Artificial Intelligence (IJCAI), 2020
      <br>
      [<a href="https://www.ijcai.org/Proceedings/2020/0094.pdf" target="_blank">pdf</a>]                    
      [<a href="https://arxiv.org/abs/2001.08565" target="_blank">arXiv</a>]
      [<a href="https://github.com/lmbxmu/abcpruner" target="_blank">code</a>]
    </td>
  </tr>

  <tr>
    <td class="pub_td1">003<img src="./imgs/bsodh.jpg" class="papericon"></td>
    <td class="pub_td2"> <font color="goldenrod">Mingbao Lin</font>, Rongrong Ji<sup>✉</sup>, Hong Liu, Xiaoshuai Sun, Yongjian Wu, Yunsheng Wu
      <br><b>Towards Optimal Discrete Online Hashing with Balanced Similarity</b>
      <br>AAAI Conference on Artificial Intelligence (AAAI), 2019
      <br>
      [<a href="https://aaai.org/ojs/index.php/AAAI/article/view/4896" target="_blank">pdf</a>]                    
      [<a href="https://arxiv.org/abs/1901.10185" target="_blank">arXiv</a>]
      [<a href="https://github.com/lmbxmu/mycode" target="_blank">code</a>]
    </td>
  </tr>
  
  <tr>
    <td class="pub_td1">002<img src="./imgs/hcoh.jpg" class="papericon"></td>
    <td class="pub_td2"> <font color="goldenrod">Mingbao Lin</font>, Rongrong Ji<sup>✉</sup>, Hong Liu, Yongjian Wu
      <br><b>Supervised Online Hashing via Hadamard Codebook Learning</b>
      <br>ACM International Conference on Multimedia (ACM MM, Oral), 2018
      <br>
      [<a href="https://dl.acm.org/doi/10.1145/3240508.3240519" target="_blank">pdf</a>]                    
      [<a href="https://arxiv.org/abs/1905.03694" target="_blank">arXiv</a>]
      [<a href="https://github.com/lmbxmu/mycode" target="_blank">code</a>]
    </td>
  </tr>
 
  <tr>
    <td class="pub_td1">001<img src="./imgs/dense.png" class="papericon"></td>
    <td class="pub_td2">Hong Liu<sup>*</sup>, <font color="goldenrod">Mingbao Lin</font><sup>*</sup>, Shengchuan Zhang, Yongjian Wu, Feiyue Huang, Rongrong Ji<sup>✉</sup>
      <br><b>Dense Auto-Encoder Hashing for Robust Cross-Modality Retrieval</b>
      <br>ACM International Conference on Multimedia (ACM MM), 2018
      <br>
      [<a href="https://dl.acm.org/doi/10.1145/3240508.3240684" target="_blank">pdf</a>]                    
      [<a href="https://github.com/LynnHongLiu/DAH" target="_blank">code</a>] 
	  (<sup>*</sup> Equal Contribution)
    </td>
  </tr>

  </tbody>
</table>


<!--
<h3>Preprint</h3>
<table class="pub_table">
  <tbody>
  
 
  <tr>
    <td class="pub_td1">014<img src="./imgs/low-rank.png" class="papericon"></td>
    <td class="pub_td2">Ziran Qin, <font color="goldenrod">Mingbao Lin</font>, Weiyao Lin<sup>✉</sup>
      <br><b>Low-Rank Winograd Transformation for 3D Convolutional Neural Networks</b>
      <br>arXiv preprint arXiv:2301.11180, 2023
      <br>
	  [<a href="https://arxiv.org/abs/2301.11180" target="_blank">arXiv</a>]
	  [<a href="#" target="_blank">code coming</a>]
    </td>
  </tr>   
  
  
  <tr>
    <td class="pub_td1">013<img src="./imgs/dcd.png" class="papericon"></td>
    <td class="pub_td2">Tie Hu, <font color="goldenrod">Mingbao Lin</font>, Lizhou You, Fei Chao, Rongrong Ji<sup>✉</sup>
      <br><b>Discriminator-Cooperated Feature Map Distillation for GAN Compression</b>
      <br>arXiv preprint arXiv:2212.14169, 2022
      <br>
	  [<a href="https://arxiv.org/abs/2212.14169" target="_blank">arXiv</a>]
	  [<a href="https://github.com/poopit/DCD-official" target="_blank">code</a>]
    </td>
  </tr>  

 
  <tr>
    <td class="pub_td1">012<img src="./imgs/crd.png" class="papericon"></td>
    <td class="pub_td2">Lizhou You, <font color="goldenrod">Mingbao Lin</font>, Tie Hu, Fei Chao, Rongrong Ji<sup>✉</sup>
      <br><b>Exploring Content Relationships for Distilling Efficient GANs</b>
      <br>arXiv preprint arXiv:2212.11091, 2022
      <br>
	  [<a href="https://arxiv.org/abs/2212.11091" target="_blank">arXiv</a>]
	  [<a href="https://github.com/TheKernelZ/CRD" target="_blank">code</a>]
    </td>
  </tr>  

  <tr>
    <td class="pub_td1">011<img src="./imgs/smmix.png" class="papericon"></td>
    <td class="pub_td2">Mengzhao Chen, <font color="goldenrod">Mingbao Lin</font>, Zhihang Lin, Yuxin Zhang, Fei Chao, Rongrong Ji<sup>✉</sup>
      <br><b>SMMix: Self-Motivated Image Mixing for Vision Transformers</b>
      <br>arXiv preprint arXiv:2212.12977, 2022
      <br>
	  [<a href="https://arxiv.org/abs/2212.12977" target="_blank">arXiv</a>]
	  [<a href="https://github.com/ChenMnZ/SMMix" target="_blank">code</a>]
    </td>
  </tr>     
  
  <tr>
    <td class="pub_td1">010<img src="./imgs/hqss.png" class="papericon"></td>
    <td class="pub_td2">Yunshan Zhong, <font color="goldenrod">Mingbao Lin</font>, Lizhou You, Yuxin Zhang, Luoqi Liu, Rongrong Ji<sup>✉</sup>
      <br><b>Shadow Removal by High-Quality Shadow Synthesis</b>
      <br>arXiv preprint arXiv:2212.04108, 2022
      <br>
	  [<a href="https://arxiv.org/abs/2212.04108" target="_blank">arXiv</a>]
	  [<a href="https://github.com/zysxmu/HQSS" target="_blank">code</a>]
    </td>
  </tr>  

  <tr>
    <td class="pub_td1">009<img src="./imgs/lts.png" class="papericon"></td>
    <td class="pub_td2">Yunshan Zhong, <font color="goldenrod">Mingbao Lin</font>, Yuxin Zhang, Gongrui Nan, Fei Chao, Rongrong Ji<sup>✉</sup>
      <br><b>Exploiting the Partly Scratch-off Lottery Ticket for Quantization-Aware Training</b>
      <br>arXiv preprint arXiv:2211.08544, 2022
      <br>
	  [<a href="https://arxiv.org/abs/2211.08544" target="_blank">arXiv</a>]
	  [<a href="https://github.com/zysxmu/LTS" target="_blank">code</a>]
    </td>
  </tr>  	  

  <tr>
    <td class="pub_td1">008<img src="./imgs/medet.png" class="papericon"></td>
    <td class="pub_td2">Peixian Chen<sup>*</sup>, Kekai Sheng<sup>*</sup>, Mengdan Zhang<sup>✉</sup>, <font color="goldenrod">Mingbao Lin</font>, Yunhang Shen, Shaohui Lin, Bo Ren, Ke Li
      <br><b>Open Vocabulary Object Detection with Proposal Mining and Prediction Equalization</b>
      <br>arXiv preprint arXiv:2206.11134, 2022
      <br>
	  [<a href="https://arxiv.org/abs/2206.11134" target="_blank">arXiv</a>]
	  [<a href="https://github.com/PeixianChen/MEDet" target="_blank">code</a>]
	  (<sup>*</sup> Equal Contribution)
    </td>
  </tr>  	 
  
  <tr>
    <td class="pub_td1">007<img src="./imgs/lab-net.png" class="papericon"></td>
    <td class="pub_td2">Hong Yang<sup>*</sup>, Gongrui Nan<sup>*</sup>, <font color="goldenrod">Mingbao Lin</font>, Fei Chao<sup>✉</sup>, Rongrong Ji
      <br><b>LAB-Net: LAB Color-Space Oriented Lightweight Network for Shadow Removal</b>
      <br>arXiv preprint arXiv:2208.13039, 2022
      <br>
	  [<a href="https://arxiv.org/abs/2208.13039" target="_blank">arXiv</a>]
	  [<a href="https://github.com/ngrxmu/lab-net" target="_blank">code</a>]
	  (<sup>*</sup> Equal Contribution)
    </td>
  </tr>  
   	
	  
  <tr>
    <td class="pub_td1">006<img src="./imgs/supervit.png" class="papericon"></td>
    <td class="pub_td2"><font color="goldenrod">Mingbao Lin</font><sup>*</sup>, Mengzhao Chen<sup>*</sup>, Yuxin Zhang, Ke Li, Yunhang Shen, Chunhua Shen, Rongrong Ji<sup>✉</sup>
      <br><b>Super Vision Transformer</b>
      <br>arXiv preprint arXiv:2205.11397, 2022
      <br>
	  [<a href="https://arxiv.org/abs/2205.11397" target="_blank">arXiv</a>]
	  [<a href="https://github.com/lmbxmu/SuperViT" target="_blank">code</a>]
	  [<a href="https://blog.csdn.net/qq_45122568/article/details/125480313" target="_blank">CSDN博客</a>]
	  (<sup>*</sup> Equal Contribution)	
    </td>
  </tr>   	  
	  
  <tr>
    <td class="pub_td1">005<img src="./imgs/sadc.png" class="papericon"></td>
    <td class="pub_td2">Yimin Xu, <font color="goldenrod">Mingbao Lin</font>, Hong Yang, Fei Chao, Rongrong Ji<sup>✉</sup>
      <br><b>Shadow-Aware Dynamic Convolution for Shadow Removal</b>
      <br>arXiv preprint arXiv:2205.04908, 2022
      <br>
	  [<a href="https://arxiv.org/abs/2205.04908" target="_blank">arXiv</a>]
	  [<a href="https://github.com/xuyimin0926/SADC" target="_blank">code</a>]
    </td>
  </tr>   	  

  <tr>
    <td class="pub_td1">004<img src="./imgs/optg.png" class="papericon"></td>
    <td class="pub_td2"> Yuxin Zhang, <font color="goldenrod">Mingbao Lin</font>, Mengzhao Chen, Fei Chao, Rongrong Ji<sup>✉</sup>
      <br><b>OptG: Optimizing Gradient-driven Criteria in Network Sparsity</b>
      <br>arXiv preprint arXiv:2201.12826, 2022
      <br>
      [<a href="https://arxiv.org/abs/2201.12826" target="_blank">arXiv</a>]                    
      [<a href="https://github.com/zyxxmu/OptG" target="_blank">code</a>]
    </td>
  </tr>

  <tr>
    <td class="pub_td1">003<img src="./imgs/pssnet.png" class="papericon"></td>
    <td class="pub_td2"> Bohong Chen, <font color="goldenrod">Mingbao Lin</font>, Liujuan Cao<sup>✉</sup>, Rongrong Ji
      <br><b>Prioritized Subnet Sampling for Resource-Adaptive Supernet Training</b>
      <br>arXiv preprint arXiv:2109.05432, 2021
      <br>              
      [<a href="https://arxiv.org/abs/2109.05432" target="_blank">arXiv</a>]
      [<a href="https://github.com/chenbong/PSS-Net" target="_blank">code</a>]	  
    </td>
  </tr>
 
  <tr>
    <td class="pub_td1">002<img src="./imgs/dcff.jpg" class="papericon"></td>
    <td class="pub_td2"><font color="goldenrod">Mingbao Lin</font>, Bohong Chen, Fei Chao, Rongrong Ji<sup>✉</sup>
      <br><b>Training Compact CNNs for Image Classification using Dynamic-coded Filter Fusion</b>
      <br>arXiv preprint arXiv:2107.06916, 2021
      <br>
      [<a href="https://arxiv.org/abs/2107.06916" target="_blank">arXiv</a>]	  
      [<a href="https://github.com/lmbxmu/DCFF" target="_blank">code</a>]                    
    </td>
  </tr>
  
  <tr>
    <td class="pub_td1">001<img src="./imgs/jackpot.jpg" class="papericon"></td>
    <td class="pub_td2">Yuxin Zhang, <font color="goldenrod">Mingbao Lin</font>, Yunshan Zhong, Fei Chao, Rongrong Ji<sup>✉</sup>
      <br><b>Lottery Jackpots Exist in Pre-trained Models</b>
      <br>arXiv preprint arXiv:2104.08700, 2021
      <br>
      [<a href="https://arxiv.org/abs/2104.08700" target="_blank">arXiv</a>]	  
      [<a href="https://github.com/zyxxmu/lottery-jackpots" target="_blank">code</a>]                    
    </td>
  </tr>   

  </tbody>
</table>
-->



<h2>Professional Activities<a name="activities"></a>&nbsp;&nbsp;&nbsp;<a style=" color:#9D849A; font-size:15px;" href="#top">[back top]</a></h2>
<ul>
    <li>Conference Reviewer: </li>
	IEEE/CVF Computer Vision and Pattern Recognition (CVPR), 2021--2023. </br>
	IEEE/CVF International Conference on Computer Vision (ICCV), 2021. <br/>
	European Conference on Computer Vision (ECCV), 2022. <br/>
	International Conference on Machine Learning (ICML), 2021--2023. <br/>
	Conference on Neural Information Processing Systems (NeurIPS), 2022. <br/>
	Association for the Advancement of Artificial Intelligence (AAAI), 2021--2023. <br/>
	
    <li>Journal Reviewer: </li>
	IEEE Transactions on Pattern Analysis and Machine Intelligence (IEEE TPAMI). <br/>
	International Journal of Computer Vision (IJCV). <br/>
	Journal of Machine Learning Research (JMLR). <br/>
	IEEE Transactions on Image Processing (IEEE TIP). <br/>
	IEEE Transactions on Neural Networks and Learning Systems (IEEE TNNLS). <br/>
	IEEE Transactions on Multimedia (IEEE TMM). <br/>
	IEEE Transactions on Circuits and Systems for Video Technology (IEEE TCSVT). <br/>
	IEEE Transactions on Network Science and Engineering (IEEE TNSE). <br/>
	Pattern Recognition (PR). <br/>
	Neurocomputing (NEUCOM). <br/>
	Neural Networks (NEUNET). <br/>
	Neural Computing and Applications (NCAA). <br/>
	Applied Intelligence (APIN). <br/>
	Artificial Intelligence Review. <br/>
	Science China Information Sciences (SCIS). <br/>
    Journal of Visual Communication and Image Representation (JVCI). <br/>
	Applied Soft Computing Journal (ASOC). <br/>
</ul>

<h2>Major Awards<a name="awards"></a>&nbsp;&nbsp;&nbsp;<a style=" color:#9D849A; font-size:15px;" href="#top">[back top]</a></h2>
<ul>
    <li>Outstanding Contributions, IEEE Standard 2941<sup style="vertical-align:top;"><font style="font-size:1px">TM</font></sup> - 2022, 2022</li>
    <li>Outstanding Ph.D. Graduate Student, Xiamen University, 2022</li>
	<li>Outstanding Merit Student, Xiamen University, 2021</li>
    <li>National Scholarship (Ph.D.), China, 2021</li>
    <li>National Scholarship (Ph.D.), China, 2020</li>
    <li>Xiamen University Scholarship, 2019</li>
</ul>

<h2>Statistics<a name="statistics"></a>&nbsp;&nbsp;&nbsp;<a style=" color:#9D849A; font-size:15px;" href="#top">[back top]</a></h2>
<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=080808&w=200&t=n&d=RWWgiUy0M5WxVvFN_4iRBNH8ObGL53aJVu9LE2BcjkA&co=ffffff&cmo=3acc3a&cmn=ff5353&ct=808080'>
</script>

</div>
</div>
</body>
</html>
