<!DOCTYPE html>
<br><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta content="IE=5.0000" http-equiv="X-UA-Compatible">
  <meta name="description" content="MingBao Lin&#39;s home page">
  <meta name="keywords" content="林明宝, Mingbao Lin" />
  
  <link href="./imgs/tlzdoc.css" rel="stylesheet" type="text/css">
  <title>Mingbao Lin's Homepage--林明宝的个人主页</title>
  <meta name="GENERATOR" content="MSHTML 11.00.10570.1001">
</head>


<br>
  <br id="layout-content" style="margin-top: 25px;">
  <table>
    <tbody>
    <tr>
      <td width="670">
        <div id="toptitle">
        <h1>&nbsp;&nbsp;&nbsp; Mingbao Lin &nbsp; 林明宝<a name="top"></a></h1>
		</div>
         &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Research Scientist <br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Kunlun 2050 Research | Skywork AI<br><br>
         &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Industry Supervisor <br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; AI Institute | Xiamen University<br>
        <p>
        <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Email: linmb001[at]outlook[dot]com <br>
        <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; See My Publications <a href="https://scholar.google.com/citations?user=Dp3L1bsAAAAJ&hl=en&oi=ao" target="_blank">[Google Scholar]</See>	
	    <br><br></p>
		&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  <!--<font color="red">updated on 31/03/2024</font> -->
      </td>
    </tr>
	</tbody>
  </table>

<ul>  
  <li> 04/2024 -- Now: Research Scientist, <a href="https://www.kunlun.com/research/en/index.html" target = "_blank">Kunlun 2050  Research</a> | Skywork AI led by <a href="https://yanshuicheng.info/" target = "_blank">Shuicheng Yan</a>, Singapore 
	<div style="font-size: small;">
		Multimodal Model (MLLM, Diffusion) for multimodal tasks (Foundation Model Training, Training-Free/Tuning-Efficient Editting) </br>
		Model Compression/Inference Acceleration/Training Efficiency on CV (ViT, <i>etc</i>.), NLP (LLM <i>etc</i>.) and Multimodal (MLLM, Diffusion  <i>etc</i>.) models.
	</div> 
  </li>

  <li> 07/2022 -- 04/2024: Senior Researcher, <a href="https://open.youtu.qq.com/#/open", target="_blank">Youtu Lab</a> | Tencent, Shanghai, China 
	<div style="font-size: small;">
		Large Language Model (LLM) for general NLP tasks (Foundation Model Training, Downstream Applications) </br>
		Model Compression on CV (CNN, ViT, <i>etc</i>.) and NLP (Bert, <i>etc</i>.) models for general tasks (Recognition, OCR, <i>etc</i>.)
	</div> 
  </li>
  
  <li> 09/2019 -- 06/2022: Research Intern, <a href = "https://www.pcl.ac.cn/index.html", target="_blank">Peng Cheng Lab</a>, Shenzhen, China 
	<div style="font-size: small;">
		Model Compression (Quantization, Pruning, Sparsity, Distillation, <i>etc</i>.) on general CV models (CNN, ViT) </br>
		Low-level CV (Super-Resolution, Shadow Removal, Demoir&eacuteing, <i>etc</i>.)
	</div> 
  </li>
  
  <li> 09/2016 -- 06/2022: M.S.-Ph.D. in Comput. Sci., <a href="https://mac.xmu.edu.cn/"  target="_blank">MAC Lab</a> led by <a href="https://mac.xmu.edu.cn/rrji/"   target="_blank">Rongrong Ji</a>, Xiamen University, China
	<div style="font-size: small;">
	    Model Compression (Quantization, Pruning, Sparsity, Distillation, <i>etc</i>.) on general CV models (CNN, ViT) </br>
		Low-level CV (Super-Resolution, Shadow Removal, Demoir&eacuteing, <i>etc</i>.) </br>
		Image/text retrieval
	</div> 
  </li>
  
  
  <li> 09/2012 -- 06/2016: B.S. in Comput. Sci., Fuzhou University, Fuzhou, China </li>
</ul>

</div>
</div>
</body>
</html>